{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bài thực hành số 5.1\n",
    "\n",
    "Chào mừng đến với bài thực hành số 5.1, đây sẽ là phần tiếp diễn của bài thực hành thứ 5 trên colab. Qua bài thực hành này, chúng tôi sẽ giúp bạn biết các áp dụng model vừa được train vào việc nhận dạng vật thể trong video hoặc qua camera laptop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hướng dẫn\n",
    "\n",
    "Dưới đây là hướng dẫn chi tiết các bước để bạn có thể hiểu được quá trình áp dụng DeepSORT và YOLO lên video.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cài đặt thư viện cần thiết"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "import math\n",
    "import time\n",
    "import pathlib\n",
    "temp = pathlib.PosixPath\n",
    "pathlib.PosixPath = pathlib.WindowsPath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tải model nhận diện"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hàm `torch.hub.load` trong PyTorch là một công cụ mạnh mẽ để tải các mô hình hoặc module từ các kho lưu trữ (repositories) đã được chia sẻ trên GitHub. Nó cho phép bạn dễ dàng sử dụng các mô hình đã được huấn luyện sẵn hoặc module khác mà không cần phải tự xây dựng từ đầu.\n",
    "\n",
    "Cấu trúc của hàm `torch.hub.load`\n",
    "\n",
    "model = torch.hub.load(repo_or_dir, model, *args, **kwargs)\n",
    "\n",
    "Tham số của hàm:\n",
    "\n",
    "1. **`repo_or_dir`**: \n",
    "   - Đây là tham số chỉ định kho lưu trữ GitHub chứa mô hình bạn muốn tải. Nó được cung cấp dưới dạng một chuỗi, ví dụ: `'ultralytics/yolov5'`.\n",
    "   - Bạn cũng có thể chỉ định đường dẫn cục bộ đến thư mục chứa mô hình nếu mô hình đã được tải xuống.\n",
    "\n",
    "2. **`model`**: \n",
    "   - Tên của mô hình hoặc module mà bạn muốn tải từ kho lưu trữ. Ví dụ: `'custom'` cho mô hình tùy chỉnh hoặc `'yolov5s'` cho mô hình YOLOv5s đã được huấn luyện sẵn.\n",
    "   - Tùy thuộc vào kho lưu trữ, tên này có thể đại diện cho một mô hình cụ thể hoặc một tập hợp các mô hình đã được định nghĩa trước.\n",
    "\n",
    "3. **`path`**: \n",
    "   - Đường dẫn đến file `.pt` chứa trọng số của mô hình đã được huấn luyện. Tham số này thường được sử dụng khi bạn muốn tải một mô hình đã được huấn luyện trước mà bạn tự xây dựng hoặc tùy chỉnh.\n",
    "\n",
    "4. **`force_reload`**: \n",
    "   - Tham số này có giá trị boolean (`True` hoặc `False`).\n",
    "   - Khi `force_reload=True`, hàm sẽ tải lại mô hình từ kho lưu trữ hoặc đường dẫn được cung cấp ngay cả khi mô hình đã được tải trước đó. Điều này rất hữu ích khi bạn muốn tránh xung đột hoặc đảm bảo rằng bạn đang sử dụng phiên bản mô hình mới nhất."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bài tập 1: Hoàn thành đoạn code sau bằng việc điền vào [...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# force reload: tránh xung đột tham số khi load model mới\n",
    "model = torch.hub.load('ultralytics/yolov5', [...], path= [...], force_reload = [...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# force reload: tránh xung đột tham số khi load model mới\n",
    "model = torch.hub.load('ultralytics/yolov5', 'custom', path= r\"D:\\Summer 2024\\Capstone project\\Lab\\YOLOv5 Test\\custom_yolov5_car_v2\\weights\\best.pt\", force_reload = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test với hình ảnh\n",
    "\n",
    "Trước khi làm việc với video, chúng ta sẽ thử áp dụng với một vài ảnh để thấy được hiệu quả của model.\n",
    "\n",
    "**`model(img_path)`**: Dòng lệnh này sử dụng mô hình YOLOv5 đã được tải từ trước để phát hiện các đối tượng trong hình ảnh.\n",
    "  - **`img_path`** là đường dẫn đến hình ảnh mà bạn muốn chạy phát hiện đối tượng.\n",
    "  - Khi bạn gọi mô hình với một đường dẫn hình ảnh như thế này, mô hình sẽ xử lý hình ảnh và trả về các kết quả phát hiện dưới dạng một đối tượng `results`.\n",
    "\n",
    "**`test_detect.show()`**: Phương thức này sẽ hiển thị hình ảnh với các hộp giới hạn (bounding boxes) được vẽ lên các đối tượng đã phát hiện.\n",
    "  - Các đối tượng phát hiện được hiển thị cùng với các thông tin như nhãn lớp và độ tin cậy của từng đối tượng.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = [...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(img_path)\n",
    "\n",
    "# Hiển thị hình ảnh sau khi đổi kích thước\n",
    "cv2.imshow(\"test\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_detect = model(img_path)\n",
    "test_detect.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Áp dụng với video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bài tập 2: Hoàn thành bài tập sau bằng cách điền vào [...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đọc video đầu vào\n",
    "input_video_path = [...]  # Đường dẫn đến video đầu vào\n",
    "output_video_path = [...]  # Đường dẫn đến video đầu ra\n",
    "\n",
    "# Mở video đầu vào\n",
    "cap = cv2.VideoCapture(input_video_path)\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video.\")\n",
    "    exit()\n",
    "\n",
    "# Lấy thông số của video\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# Tạo video writer để lưu video đầu ra\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec cho định dạng MP4\n",
    "out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Chuyển đổi khung hình từ BGR sang RGB\n",
    "    rgb_frame = [...]\n",
    "\n",
    "    # Dự đoán với YOLOv5\n",
    "    results = model([...])\n",
    "\n",
    "    # Lấy kết quả dự đoán dưới dạng DataFrame\n",
    "    df = results.pandas().xyxy[0]\n",
    "\n",
    "    # Vẽ các hộp dự đoán lên khung hình\n",
    "    for _, row in df.iterrows():\n",
    "        x1, y1, x2, y2 = int(row['xmin']), int(row['ymin']), int(row['xmax']), int(row['ymax'])\n",
    "        label = row['name']\n",
    "        score = row['confidence']\n",
    "        \n",
    "        # Vẽ hộp bounding box\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        # Vẽ nhãn lớp và độ tin cậy\n",
    "        cv2.putText(frame, f'{label} {score:.2f}', (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "    # Ghi khung hình vào video đầu ra\n",
    "    out.write(frame)\n",
    "\n",
    "# Giải phóng tài nguyên\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đọc video đầu vào\n",
    "input_video_path = r\"D:\\Summer 2024\\Capstone project\\Lab\\YOLOv5 Test\\Test_video\\test_car_2.mp4\"  # Đường dẫn đến video đầu vào\n",
    "output_video_path = r\"D:\\Summer 2024\\Capstone project\\Lab\\YOLOv5 Test\\Test_video\\test_car_2_output.mp4\"  # Đường dẫn đến video đầu ra\n",
    "\n",
    "# Mở video đầu vào\n",
    "cap = cv2.VideoCapture(input_video_path)\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video.\")\n",
    "    exit()\n",
    "\n",
    "# Lấy thông số của video\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# Tạo video writer để lưu video đầu ra\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec cho định dạng MP4\n",
    "out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Chuyển đổi khung hình từ BGR sang RGB\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Dự đoán với YOLOv5\n",
    "    results = model(rgb_frame)\n",
    "\n",
    "    # Lấy kết quả dự đoán dưới dạng DataFrame\n",
    "    df = results.pandas().xyxy[0]\n",
    "\n",
    "    # Vẽ các hộp dự đoán lên khung hình\n",
    "    for _, row in df.iterrows():\n",
    "        x1, y1, x2, y2 = int(row['xmin']), int(row['ymin']), int(row['xmax']), int(row['ymax'])\n",
    "        label = row['name']\n",
    "        score = row['confidence']\n",
    "        \n",
    "        # Vẽ hộp bounding box\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        # Vẽ nhãn lớp và độ tin cậy\n",
    "        cv2.putText(frame, f'{label} {score:.2f}', (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "    # Ghi khung hình vào video đầu ra\n",
    "    out.write(frame)\n",
    "\n",
    "# Giải phóng tài nguyên\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
