{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3.3: Phát hiện biển báo giao thông\n",
    "\n",
    "Chào mừng bạn đến với Lab 3.3. Trong bài lab này, chúng ta sẽ học cách sử dụng mô hình YOLO đã được huấn luyện trước để phát hiện phương tiện.\n",
    "\n",
    "## Hướng dẫn\n",
    "\n",
    "Dưới đây là hướng dẫn chi tiết để giúp bạn lập trình và chạy chương trình theo dõi phương tiện.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thư viện"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import pathlib\n",
    "# Ensure proper path handling for Windows\n",
    "temp = pathlib.PosixPath\n",
    "pathlib.PosixPath = pathlib.WindowsPath\n",
    "\n",
    "# Handle library conflicts\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VehicleDetector():\n",
    "    def __init__(self, model_path, force_reload):\n",
    "        self.model = self.load_model(model_path, force_reload)\n",
    "        self.classes = self.model.names\n",
    "        print(self.classes)\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.model.to(self.device)\n",
    "        print(\"Using Device: \", self.device)\n",
    "\n",
    "    def load_model(self, model_path, force_reload):\n",
    "        if model_path:\n",
    "            model = torch.hub.load(\n",
    "                'ultralytics/yolov5',\n",
    "                'custom',\n",
    "                path=model_path,\n",
    "                force_reload=force_reload\n",
    "            )\n",
    "        else:\n",
    "            model = torch.hub.load(\n",
    "                'ultralytics/yolov5',\n",
    "                'yolov5s',\n",
    "                pretrained=True\n",
    "            )\n",
    "\n",
    "        return model\n",
    "\n",
    "    def score_frame(self, frame):\n",
    "        frame_rgb = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "        results = self.model(frame_rgb)\n",
    "\n",
    "        labels, cord = results.xyxyn[0][:, -1], results.xyxyn[0][:, :-1]\n",
    "\n",
    "        return labels, cord\n",
    "\n",
    "    def class_to_label(self, x):\n",
    "        return self.classes[int(x)]\n",
    "\n",
    "    def plot_boxes(self, results, height, width, confidence=0.3):\n",
    "        labels, cord = results\n",
    "        detections = []\n",
    "\n",
    "        for i in range(len(labels)):\n",
    "            row = cord[i]\n",
    "            if row[4] >= confidence:\n",
    "                x1, y1, x2, y2 = int(\n",
    "                    row[0]*width), int(row[1]*height), int(row[2]*width), int(row[3]*height)\n",
    "\n",
    "                conf = float(row[4].item())\n",
    "                class_label = self.class_to_label(labels[i])\n",
    "                # print(feature)\n",
    "                detections.append(\n",
    "                    ([x1, y1, int(x2-x1), int(y2-y1)], conf, class_label))\n",
    "\n",
    "        return detections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Triển khai Mô hình YOLOv5 đã huấn luyện trước và DeepSORT\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Đáp án bài tập 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
    "ip_lap_lead = \"192.168.109.105\"\n",
    "port_lap_lead = 7001\n",
    "\n",
    "ip_lap = \"192.168.109.105\"\n",
    "port_lap = 3000\n",
    "\n",
    "# Define the path to the YOLO model weights for traffic sign detection\n",
    "model_path = r'..\\Other\\YoloWeights\\VehicleDetect.pt'\n",
    "\n",
    "# Initialize the traffic sign detector with the specified model path\n",
    "vehicle_detector = VehicleDetector(\n",
    "    model_path=model_path, force_reload=True)\n",
    "\n",
    "# Initialize the object tracker with specified parameters\n",
    "object_tracker = DeepSort(\n",
    "    max_age=3, n_init=2, nms_max_overlap=1.0, max_cosine_distance=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket\n",
    "BUFFER_SIZE = 65355\n",
    "\n",
    "\n",
    "def create_udp_socket_listen(ip, port):\n",
    "    \"\"\"Create and bind a UDP socket listening\"\"\"\n",
    "    sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n",
    "    sock.bind((ip, port))\n",
    "    return sock\n",
    "\n",
    "\n",
    "def create_udp_socket_send():\n",
    "    \"\"\"Create and bind a UDP socket for sending\"\"\"\n",
    "    sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n",
    "    sock.setsockopt(socket.SOL_SOCKET, socket.SO_BROADCAST, BUFFER_SIZE)\n",
    "    return sock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from queue import Queue\n",
    "\n",
    "END_MARKER = b'\\xff\\xd9'\n",
    "IMAGE_RESIZE_DIMS = (1280, 720)\n",
    "queue_image = Queue()\n",
    "MAX_QUEUE_SIZE = 3\n",
    "\n",
    "\n",
    "def get_image_from_cam():\n",
    "    \"\"\"Receive images via UDP and put them in the queue.\"\"\"\n",
    "    global stop_event\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "\n",
    "    while cap.isOpened() and (not stop_event.is_set()):\n",
    "        _, image = cap.read()\n",
    "        queue_image.put(image)\n",
    "\n",
    "        if queue_image.qsize() >= MAX_QUEUE_SIZE:\n",
    "            queue_image.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_from_leader():\n",
    "    \"\"\"Receive images via UDP and put them in the queue.\"\"\"\n",
    "    global stop_event\n",
    "\n",
    "    sock = create_udp_socket_listen(ip_lap, port_lap)\n",
    "    print(f\"Listening on IP {ip_lap}, UDP port {port_lap}\")\n",
    "\n",
    "    image_data = bytearray()\n",
    "    while not stop_event.is_set():\n",
    "        data, _ = sock.recvfrom(BUFFER_SIZE)\n",
    "        image_data.extend(data)\n",
    "\n",
    "        if data.endswith(END_MARKER):\n",
    "            try:\n",
    "                image_array = np.frombuffer(image_data, dtype=np.uint8)\n",
    "                image = cv2.imdecode(image_array, cv2.IMREAD_COLOR)\n",
    "                queue_image.put(image)\n",
    "\n",
    "                if queue_image.qsize() >= MAX_QUEUE_SIZE:\n",
    "                    queue_image.get()\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to convert image: {str(e)}\")\n",
    "\n",
    "            image_data = bytearray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Define Direction constants\n",
    "STRAIGHT = 1\n",
    "SLOW = 2\n",
    "TURNLEFT = 5\n",
    "TURNRIGHT = 6\n",
    "FORWARD = 7\n",
    "BACKWARD = 8\n",
    "STANDBY = 9\n",
    "STOP = 10\n",
    "\n",
    "\n",
    "def detect_vehicle():\n",
    "    prev_time = time.time()\n",
    "    frame_count = 0\n",
    "    fps = 0\n",
    "    prev_cmd = STOP\n",
    "\n",
    "    sock = create_udp_socket_send()\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            image = queue_image.get()\n",
    "\n",
    "            frame_count += 1\n",
    "            tmp_time = time.time() - prev_time\n",
    "            if tmp_time >= 1:\n",
    "                fps = frame_count / tmp_time\n",
    "                prev_time = time.time()\n",
    "                frame_count = 0\n",
    "\n",
    "            results = vehicle_detector.score_frame(image)\n",
    "            detections = vehicle_detector.plot_boxes(\n",
    "                results, height=image.shape[0], width=image.shape[1], confidence=0.5)\n",
    "            tracks = object_tracker.update_tracks(detections, frame=image)\n",
    "\n",
    "            cmd = STRAIGHT\n",
    "            for track in tracks:\n",
    "                if not track.is_confirmed():\n",
    "                    continue\n",
    "                track_id = track.track_id\n",
    "                bbox_x1, bbox_y1, bbox_x2, bbox_y2 = map(int, track.to_ltrb())\n",
    "                class_label = track.det_class\n",
    "                conf = track.det_conf if track.det_conf is not None else 0.0\n",
    "\n",
    "                if bbox_y2 >= image.shape[0] - 100:\n",
    "                    cmd = STOP\n",
    "\n",
    "                    # Change color\n",
    "                    cv2.rectangle(image, (bbox_x1, bbox_y1),\n",
    "                                  (bbox_x2, bbox_y2), (0, 255, 0), 2)\n",
    "                else:\n",
    "                    # Normal tracking display\n",
    "                    cv2.rectangle(image, (bbox_x1, bbox_y1),\n",
    "                                  (bbox_x2, bbox_y2), (0, 0, 255), 2)\n",
    "\n",
    "                cv2.putText(image, \"ID: \" + str(track_id), (bbox_x1, bbox_y1 - 10),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "                cv2.putText(image, f'Class: {\n",
    "                            class_label}', (bbox_x1, bbox_y1 - 45), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "                cv2.putText(image, f'Conf: {\n",
    "                    conf:.2f}', (bbox_x1, bbox_y1 - 70), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"Error processing image:\", e)\n",
    "            cmd = STOP\n",
    "\n",
    "        if cmd != prev_cmd:\n",
    "            try:\n",
    "                data_cmd = f\"{cmd}\"\n",
    "                data_bytes_cmd = data_cmd.encode()\n",
    "                sock.sendto(data_bytes_cmd, (ip_lap_lead, port_lap_lead))\n",
    "                print(f\"Sent UDP message: '{cmd}' to {\n",
    "                      ip_lap_lead}:{port_lap_lead}\")\n",
    "                prev_cmd = cmd\n",
    "            except Exception as e:\n",
    "                print(f\"Error sending UDP message: {e}\")\n",
    "\n",
    "        cv2.putText(image, f'FPS: {int(fps)}', (20, 70),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 255, 0), 2)\n",
    "        cv2.imshow('image', image)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == 27:\n",
    "            break\n",
    "\n",
    "    # sock.close()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kiểm tra mô hình phát hiện phương tiện bằng cách sử dụng camera laptop\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Đáp án bài tập 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "stop_event = threading.Event()\n",
    "\n",
    "\n",
    "threads = [\n",
    "    threading.Thread(target=get_image_from_cam,\n",
    "                     name='GetSendImageThread'),\n",
    "    threading.Thread(target=detect_vehicle,\n",
    "                     name='ProcessImageThread'),\n",
    "]\n",
    "\n",
    "for thread in threads:\n",
    "    thread.start()\n",
    "\n",
    "for thread in threads:\n",
    "    thread.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Triển khai mô hình phát hiện phương tiện để điều khiển bộ AutoCar\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Đáp án bài tập 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "stop_event = threading.Event()\n",
    "\n",
    "\n",
    "threads = [\n",
    "    threading.Thread(target=get_image_from_leader,\n",
    "                     name='GetSendImageThread'),\n",
    "    threading.Thread(target=detect_vehicle,\n",
    "                     name='ProcessImageThread'),\n",
    "]\n",
    "\n",
    "for thread in threads:\n",
    "    thread.start()\n",
    "\n",
    "for thread in threads:\n",
    "    thread.join()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
