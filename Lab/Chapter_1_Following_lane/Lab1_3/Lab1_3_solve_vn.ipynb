{"cells":[{"cell_type":"markdown","metadata":{"id":"0UKu9b7N6cPF"},"source":["# Bài thực hành 1.3: Phát Hiện Làn Đường\n","\n","Chào mừng đến với bài thực hành 1.3. Trong bài thực hành này, chúng ta sẽ học cách áp dụng thuật toán Canny để phát hiện làn đường cho các phương tiện tự hành."]},{"cell_type":"markdown","metadata":{},"source":["## Hướng Dẫn\n","\n","Dưới đây là các hướng dẫn chi tiết về cách lập trình và chạy một phương tiện theo dõi làn đường."]},{"cell_type":"markdown","metadata":{"id":"L5_NBDAF6xx7"},"source":["### Thư viện"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AOim6Sv06Xjs"},"outputs":[],"source":["import numpy as np\n","import cv2\n","import glob\n","import matplotlib.image as mpimage\n","import matplotlib.pyplot as plt"]},{"cell_type":"markdown","metadata":{"id":"R7Ux9HmD7ibN"},"source":["### Hiệu chuẩn\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"umEeVMqF6Xju"},"outputs":[],"source":["import glob\n","import numpy as np\n","import cv2\n","import matplotlib.image as mpimage\n","\n","\n","class CameraCalibration():\n","    \"\"\" Camera calibration using chessboard images \"\"\"\n","\n","    def __init__(self, image_dir, nx, ny):\n","        \"\"\" Initialize the CameraCalibration class.\n","\n","        Parameters:\n","            image_dir (str): Path to the directory containing chessboard images\n","            nx (int): Number of squares in the x direction of the chessboard\n","            ny (int): Number of squares in the y direction of the chessboard\n","        \"\"\"\n","        # Get the names of all images in the directory\n","        fnames = glob.glob(\"{}/*\".format(image_dir))\n","\n","        # List of 3D points for the chessboard corners\n","        objpoints = []\n","        # List of 2D points for the chessboard corners in the images\n","        imagepoints = []\n","\n","        # Create coordinates for 3D points of the chessboard corners\n","        objp = np.zeros((nx*ny, 3), np.float32)\n","        objp[:, :2] = np.mgrid[0:nx, 0:ny].T.reshape(-1, 2)\n","\n","        # Iterate through all chessboard images\n","        for f in fnames:\n","            image = mpimage.imread(f)\n","\n","            # Find chessboard corners\n","            ret, corners = cv2.findChessboardCorners(image, (nx, ny))\n","            # If chessboard corners are found\n","            if ret:\n","                # Add the corner coordinates to the list\n","                imagepoints.append(corners)\n","                # Add the 3D coordinates to the list\n","                objpoints.append(objp)\n","\n","        # Shape of the processed images\n","        shape = (720, 1280)\n","        # Camera calibration\n","        ret, self.mtx, self.dist, _, _ = cv2.calibrateCamera(\n","            objpoints, imagepoints, shape, None, None)\n","\n","        # If calibration was unsuccessful\n","        if not ret:\n","            raise Exception(\"Unable to calibrate camera\")\n","\n","    # Correct image distortion\n","    def undistort(self, image):\n","        \"\"\" Returns an undistorted image.\n","\n","        Parameters:\n","            image (np.array): Input image\n","\n","        Returns:\n","            Image (np.array): Undistorted image\n","        \"\"\"\n","        return cv2.undistort(image, self.mtx, self.dist, None, self.mtx)"]},{"cell_type":"markdown","metadata":{},"source":["Đáp án bài tập 1"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Path to the directory containing chessboard images\n","image_dir = r'..\\Other\\CameraCalibration'\n","nx = 9\n","ny = 6\n","\n","# Initialize the camera calibration object\n","calibrator = CameraCalibration(image_dir, nx, ny)\n","\n","# Check the results\n","# Path to a chessboard image\n","example_image = cv2.imread(\n","    r'..\\Other\\CameraCalibration\\calibration1.jpg')\n","\n","# Correct the image distortion\n","undistorted_image = calibrator.undistort(example_image)\n","\n","# Convert image from BGR (OpenCV) to RGB (matplotlib)\n","example_image_rgb = cv2.cvtColor(example_image, cv2.COLOR_BGR2RGB)\n","undistorted_image_rgb = cv2.cvtColor(undistorted_image, cv2.COLOR_BGR2RGB)\n","\n","# Display the images\n","plt.figure(figsize=(12, 6))\n","\n","plt.subplot(1, 2, 1)\n","plt.title('Original Image')\n","plt.imshow(example_image_rgb)\n","plt.axis('off')\n","\n","plt.subplot(1, 2, 2)\n","plt.title('Undistorted Image')\n","plt.imshow(undistorted_image_rgb)\n","plt.axis('off')\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"qfTHpigO9aih"},"source":["### Chuyển Đổi Phép Chiếu Hình Ảnh"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3mGJGt9t6Xjv"},"outputs":[],"source":["class PerspectiveTransformation:\n","    \"\"\" Transforms images between a front view and a top-down view \"\"\"\n","\n","    def __init__(self, src, dst):\n","        self.M = cv2.getPerspectiveTransform(src, dst)\n","        self.M_inv = cv2.getPerspectiveTransform(dst, src)\n","\n","    # Transform the image to a top-down view\n","    def forward(self, image, image_size=(1280, 720), flags=cv2.INTER_LINEAR):\n","        \"\"\" Convert a front view image to a top-down view\n","\n","        Parameters:\n","            image (np.array): Front view image\n","            image_size (tuple): Size of the output image (width, height)\n","            flags : INTER_LINEAR\n","\n","        Returns:\n","            Image (np.array): Top-down view image\n","        \"\"\"\n","        return cv2.warpPerspective(image, self.M, image_size, flags=flags)\n","\n","    # Restore the image from a top-down view to the original perspective\n","    def backward(self, image, image_size=(1280, 720), flags=cv2.INTER_LINEAR):\n","        \"\"\" Convert a top-down view image to a front view\n","\n","        Parameters:\n","            image (np.array): Top-down view image\n","            image_size (tuple): Size of the output image (width, height)\n","            flags (int): INTER_LINEAR\n","\n","        Returns:\n","            Image (np.array): Front view image\n","        \"\"\"\n","        return cv2.warpPerspective(image, self.M_inv, image_size, flags=flags)"]},{"cell_type":"markdown","metadata":{},"source":["Đáp án bài tập 2"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Path to a lane image\n","example_image = cv2.imread(\n","    r\"E:\\Code\\ACE\\Lap\\Lap3\\Test Image\\Lane_line.jpg\")\n","example_image = cv2.resize(example_image, (1280, 720))\n","\n","# Define source points\n","src_points = np.float32([(430, 550),     # top-left point\n","                         (260, 650),     # bottom-left point\n","                         (1020, 650),    # bottom-right point\n","                         (850, 550)])    # top-right point\n","\n","# Define destination points\n","dst_points = np.float32([(100, 0),\n","                        (100, 720),\n","                        (1180, 720),\n","                        (1180, 0)])\n","\n","# Draw points on the image\n","image = example_image.copy()\n","# Draw source points (in blue)\n","for i, point in enumerate(src_points):\n","    cv2.circle(image, (int(point[0]), int(point[1])),\n","               5, (255, 0, 0), -1)  # Draw a filled circle\n","    cv2.putText(image, str(i+1), (int(point[0])-10, int(point[1])-10),\n","                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n","\n","# Draw destination points (in red)\n","for i, point in enumerate(dst_points):\n","    cv2.circle(image, (int(point[0]), int(point[1])),\n","               5, (0, 0, 255), -1)  # Draw a filled circle\n","    cv2.putText(image, str(i+1), (int(point[0])-10, int(point[1])-10),\n","                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n","\n","# Undistort the image\n","undistorted_image = calibrator.undistort(example_image)\n","# Convert the image to a top-down view\n","transform = PerspectiveTransformation(src_points, dst_points)\n","transform_image = transform.forward(undistorted_image)\n","\n","# Display the original image\n","plt.figure(figsize=(10, 5))\n","plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n","plt.title(\"Original Image\")\n","plt.axis('off')\n","plt.show()\n","\n","# Display the transformed image\n","plt.figure(figsize=(10, 5))\n","plt.imshow(cv2.cvtColor(transform_image, cv2.COLOR_BGR2RGB))\n","plt.title(\"Top-Down View Image\")\n","plt.axis('off')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"kazWp1Xl-Q23"},"source":["### Ngưỡng Hóa\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Compute relative threshold\n","def threshold_rel(image, lo, hi):\n","    # Compute the minimum pixel value in the image\n","    vmin = np.min(image)\n","    # Compute the maximum pixel value in the image\n","    vmax = np.max(image)\n","\n","    # Calculate the low threshold value based on the percentage 'lo'\n","    vlo = vmin + (vmax - vmin) * lo\n","    # Calculate the high threshold value based on the percentage 'hi'\n","    vhi = vmin + (vmax - vmin) * hi\n","    # Apply thresholding and convert to uint8 data type\n","    return np.uint8((image >= vlo) & (image <= vhi)) * 255\n","\n","\n","def threshold_abs(image, lo, hi):\n","    \"\"\" Define a function for absolute thresholding\n","        Apply thresholding and convert to uint8 data type\n","    \"\"\"\n","    return np.uint8((image >= lo) & (image <= hi)) * 255\n","\n","\n","class Thresholding:\n","    \"\"\" Extract relevant pixels in the image \"\"\"\n","\n","    def __init__(self):\n","        pass\n","\n","    def forward(self, image):\n","        \"\"\" Receive an image and extract all lane marking pixels.\n","\n","        Parameters:\n","            image (np.array): Input image\n","\n","        Returns:\n","            binary (np.array): Binary image representing all positions of lane marking pixels.\n","        \"\"\"\n","        # Convert the input image to HLS color space\n","        hls = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n","        # Convert the input image to HSV color space\n","        hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n","        # Extract the H (hue) channel from the HLS image\n","        h_channel = hls[:, :, 0]\n","        # Extract the S (saturation) channel from the HLS image\n","        s_channel = hls[:, :, 2]\n","        # Extract the V (value) channel from the HSV image\n","        v_channel = hsv[:, :, 2]\n","\n","        # Check if the lane markings are yellow\n","        # left_lane = threshold_abs(h_channel, 20, 30)\n","\n","        # Extract the left lane marking pixels\n","        left_lane = threshold_rel(v_channel, 0.7, 1.0)\n","\n","        # Extract the right lane marking pixels\n","        right_lane = threshold_rel(v_channel, 0.7, 1.0)\n","\n","        # Combine the thresholded images for the left and right lane markings using a logical OR\n","        result = left_lane | right_lane\n","\n","        return result  # Return the binary image with lane marking pixels"]},{"cell_type":"markdown","metadata":{},"source":["Đáp án bài tập 3"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cdUXyGXo6Xjw"},"outputs":[],"source":["# Path to the lane image\n","example_image = cv2.imread(\n","    r\"E:\\Code\\ACE\\Lap\\Lap3\\Test Image\\Lane_line.jpg\")\n","example_image = cv2.resize(example_image, (1280, 720))\n","\n","# Initialize the Thresholding class\n","thresholding = Thresholding()\n","\n","# Make a copy of the image for processing\n","image = example_image.copy()\n","# Undistort the image\n","undistort_image = calibrator.undistort(image)\n","# Transform the image to a bird's-eye view\n","bird_eye_image = transform.forward(undistort_image)\n","# Apply thresholding to the bird's-eye view image\n","thresholding_image = thresholding.forward(bird_eye_image)\n","\n","# Display the thresholded image\n","plt.figure(figsize=(10, 5))\n","plt.imshow(cv2.cvtColor(thresholding_image, cv2.COLOR_BGR2RGB))\n","plt.title(\"Lane Marking Image\")\n","plt.axis('off')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class PerspectiveTransformation:\n","    def __init__(self):\n","        self.src = np.float32([(280, 400),\n","                               (30, 650),\n","                               (1250, 650),\n","                               (1000, 400)])\n","\n","        self.dst = np.float32([(180, 0),\n","                               (180, 720),\n","                               (1100, 720),\n","                               (1100, 0)])\n","\n","        self.M = cv2.getPerspectiveTransform(self.src, self.dst)\n","        self.M_inv = cv2.getPerspectiveTransform(self.dst, self.src)\n","\n","    def forward(self, img, img_size=(1280, 720), flags=cv2.INTER_LINEAR):\n","        return cv2.warpPerspective(img, self.M, img_size, flags=flags)\n","\n","    def backward(self, img, img_size=(1280, 720), flags=cv2.INTER_LINEAR):\n","        return cv2.warpPerspective(img, self.M_inv, img_size, flags=flags)"]},{"cell_type":"markdown","metadata":{"id":"EFo4h12D-lNC"},"source":["### Phát hiện vạch kẻ đường"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7aBgLb0W6Xjx"},"outputs":[],"source":["# Control Command Constants\n","STRAIGHT = 1\n","SLOW = 2\n","LEFT = 3\n","RIGHT = 4\n","TURNLEFT = 5\n","TURNRIGHT = 6\n","FORWARD = 7\n","BACKWARD = 8\n","STANDBY = 9\n","STOP = 10\n","\n","commands = [\n","    \"Straight\",      # 1\n","    \"Slow\",         # 2\n","    \"Left\",         # 3\n","    \"Right\",        # 4\n","    \"TurnLeft\",     # 5\n","    \"TurnRight\",    # 6\n","    \"Forward\",      # 7\n","    \"Backward\",     # 8\n","    \"Standby\",      # 9\n","    \"Stop\"          # 10\n","]\n","\n","\n","# Compute the histogram of the bottom half of the image\n","def hist(image):\n","    # Select the bottom half of the image\n","    bottom_half = image[image.shape[0]//2:, :]\n","    # Compute the histogram along the horizontal axis\n","    return np.sum(bottom_half, axis=0)\n","\n","\n","# Lane line detection class\n","class LaneLines:\n","    def __init__(self):\n","        self.left_fit = None    # Polynomial coefficients for the left lane line\n","        self.right_fit = None   # Polynomial coefficients for the right lane line\n","        self.nonzero = None     # Indices of non-zero pixels\n","        self.nonzerox = None    # X coordinates of non-zero pixels\n","        self.nonzeroy = None    # Y coordinates of non-zero pixels\n","        self.dir = []           # List to store the directions of detected lane lines\n","        self.cmd = STRAIGHT     # Default command\n","\n","        self.nwindows = 9   # Number of windows to detect lane lines\n","        # Margin around the previous window to search for lane pixels\n","        self.margin = 30\n","        self.minpix = 50    # Minimum number of pixels to recenter the window\n","\n","    def forward(self, image):\n","        \"\"\" Receive an image and detect lane lines.\n","\n","        Parameters:\n","            image (np.array): Binary image containing relevant pixels\n","\n","        Returns:\n","            Image (np.array): RGB image with lane line pixels highlighted\n","        \"\"\"\n","        # Extract features from the input image\n","        self.extract_features(image)\n","        # Fit polynomial curves to the detected lane line pixels\n","        return self.fit_poly(image)\n","\n","    # Calculate pixel indices within a window\n","    def pixels_in_window(self, center, margin, height):\n","        \"\"\" Return all pixels in a specific window\n","\n","        Parameters:\n","            center (tuple): coordinates of the window center\n","            margin (int): width of the window\n","            height (int): height of the window\n","\n","        Returns:\n","            pixelx (np.array): x coordinates of pixels within the window\n","            pixely (np.array): y coordinates of pixels within the window\n","        \"\"\"\n","        # Top-left corner of the window\n","        topleft = (center[0]-margin, center[1]-height//2)\n","        # Bottom-right corner of the window\n","        bottomright = (center[0]+margin, center[1]+height//2)\n","\n","        # Condition to select pixels within the window bounds\n","        condx = (topleft[0] <= self.nonzerox) & (\n","            self.nonzerox <= bottomright[0])\n","        condy = (topleft[1] <= self.nonzeroy) & (\n","            self.nonzeroy <= bottomright[1])\n","        # Return coordinates of selected pixels\n","        return self.nonzerox[condx & condy], self.nonzeroy[condx & condy]\n","\n","    # Extract features from the binary image\n","    def extract_features(self, image):\n","        \"\"\" Extract features from a binary image\n","\n","        Parameters:\n","            image (np.array): Binary image\n","        \"\"\"\n","        # Store the input image\n","        self.image = image\n","        # Calculate the height of each window\n","        self.window_height = int(image.shape[0]//self.nwindows)\n","\n","        # Get indices of non-zero pixels in the image\n","        self.nonzero = image.nonzero()\n","        self.nonzerox = np.array(self.nonzero[1])\n","        self.nonzeroy = np.array(self.nonzero[0])\n","\n","    # Find lane pixels in the windows\n","    def find_lane_pixels(self, image):\n","        \"\"\" Find lane line pixels from a warped binary image.\n","\n","        Parameters:\n","            image (np.array): A warped binary image\n","\n","        Returns:\n","            leftx (np.array): x coordinates of left lane line pixels\n","            lefty (np.array): y coordinates of left lane line pixels\n","            rightx (np.array): x coordinates of right lane line pixels\n","            righty (np.array): y coordinates of right lane line pixels\n","            out_image (np.array): RGB image for displaying results.\n","        \"\"\"\n","        # Ensure the input image is grayscale\n","        assert (len(image.shape) == 2)\n","        # Create an image to draw the detected lane line pixels\n","        out_image = np.dstack((image, image, image))\n","\n","        # Compute the histogram of the bottom half of the image\n","        histogram = hist(image)\n","        # Calculate the midpoint of the histogram\n","        midpoint = histogram.shape[0]//2\n","        # Find the peak of the left half of the histogram\n","        leftx_base = np.argmax(histogram[:midpoint])\n","        # Find the peak of the right half of the histogram\n","        rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n","\n","        # Initialize the current x coordinate for the left lane line\n","        leftx_current = leftx_base\n","        # Initialize the current x coordinate for the right lane line\n","        rightx_current = rightx_base\n","        # Initialize the current y coordinate\n","        y_current = image.shape[0] + self.window_height//2\n","        # Initialize lists to store detected lane line pixels\n","        leftx, lefty, rightx, righty = [], [], [], []\n","\n","        # Iterate through each window\n","        for _ in range(self.nwindows):\n","            # Move the window position up\n","            y_current -= self.window_height\n","\n","            # Define the center coordinates of the current window\n","            center_left = (leftx_current, y_current)\n","            center_right = (rightx_current, y_current)\n","\n","            # Find lane line pixels in the current window\n","            good_left_x, good_left_y = self.pixels_in_window(\n","                center_left, self.margin, self.window_height)\n","            good_right_x, good_right_y = self.pixels_in_window(\n","                center_right, self.margin, self.window_height)\n","\n","            # Add the detected lane line pixels to the respective lists\n","            leftx.extend(good_left_x)\n","            lefty.extend(good_left_y)\n","            rightx.extend(good_right_x)\n","            righty.extend(good_right_y)\n","\n","            # Recenter the window if enough pixels are found\n","            if len(good_left_x) > self.minpix:\n","                leftx_current = np.int32(np.mean(good_left_x))\n","            if len(good_right_x) > self.minpix:\n","                rightx_current = np.int32(np.mean(good_right_x))\n","\n","        # Return the detected lane line pixels and the result image\n","        return leftx, lefty, rightx, righty, out_image\n","\n","    # Fit polynomial curves to the detected lane line pixels\n","    def fit_poly(self, image):\n","        \"\"\" Find the lane lines from an image and draw them.\n","\n","        Parameters:\n","            image (np.array): A warped binary image\n","\n","        Returns:\n","            out_image (np.array): An RGB image with the lane lines drawn on it.\n","        \"\"\"\n","        # Find the lane line pixels\n","        leftx, lefty, rightx, righty, out_image = self.find_lane_pixels(\n","            image)\n","        # Fit polynomial curves to the detected lane line pixels\n","        if len(lefty) > 1500:\n","            self.left_fit = np.polyfit(lefty, leftx, 2)\n","        if len(righty) > 1500:\n","            self.right_fit = np.polyfit(righty, rightx, 2)\n","\n","        # Calculate y coordinates to draw the lane lines\n","        maxy = image.shape[0] - 1\n","        miny = image.shape[0] // 3\n","        if len(lefty):\n","            maxy = max(maxy, np.max(lefty))\n","            miny = min(miny, np.min(lefty))\n","        if len(righty):\n","            maxy = max(maxy, np.max(righty))\n","            miny = min(miny, np.min(righty))\n","        ploty = np.linspace(miny, maxy, image.shape[0])\n","\n","        # Calculate x coordinates to draw the lane lines\n","        left_fitx = self.left_fit[0]*ploty**2 + \\\n","            self.left_fit[1]*ploty + self.left_fit[2]\n","        right_fitx = self.right_fit[0]*ploty**2 + \\\n","            self.right_fit[1]*ploty + self.right_fit[2]\n","\n","        # Draw the lane lines on the output image\n","        for i, y in enumerate(ploty):\n","            l = int(left_fitx[i])\n","            r = int(right_fitx[i])\n","            y = int(y)\n","            cv2.line(out_image, (l, y), (r, y), (0, 255, 0))\n","\n","        return out_image\n","\n","    # Draw the detected lane lines\n","    def plot(self, out_image):\n","        np.set_printoptions(precision=6, suppress=True)\n","        lR, rR, self.pos = self.measure_curvature()\n","        # curvature_cmd = \"Curvature = {:.0f} m\".format(min(lR, rR))\n","\n","        if (self.pos > 0.1):\n","            self.cmd = LEFT\n","        elif (self.pos < -0.1):\n","            self.cmd = RIGHT\n","        else:\n","            self.cmd = STRAIGHT\n","\n","        cv2.putText(out_image, commands[self.cmd-1], org=(10, 240), fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n","                    fontScale=1, color=(255, 255, 255), thickness=2)\n","\n","        cv2.putText(\n","            out_image,\n","            \"Vehicle is {:.2f} m away from center\".format(self.pos),\n","            org=(10, 310),\n","            fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n","            fontScale=0.66,\n","            color=(255, 255, 255),\n","            thickness=2)\n","\n","        return out_image\n","\n","    # Measure vehicle position and lane curvature\n","\n","    def measure_curvature(self):\n","        ym = 30/720  # Meters per pixel in the vertical direction\n","        xm = 3.7/700  # Meters per pixel in the horizontal direction\n","\n","        # Copy polynomial coefficients\n","        left_fit = self.left_fit.copy()\n","        right_fit = self.right_fit.copy()\n","\n","        # Calculate y coordinate to evaluate curvature\n","        y_eval = 700 * ym\n","\n","        # Calculate the curvature radius of the left lane line\n","        left_curveR = (\n","            (1 + (2*left_fit[0] * y_eval + left_fit[1])**2)**1.5) / np.absolute(2*left_fit[0])\n","\n","        # Calculate the curvature radius of the right lane line\n","        right_curveR = (\n","            (1 + (2*right_fit[0]*y_eval + right_fit[1])**2)**1.5) / np.absolute(2*right_fit[0])\n","\n","        # Calculate x coordinates of the lane lines at y=700\n","        xl = np.dot(self.left_fit, [700**2, 700, 1])\n","        xr = np.dot(self.right_fit, [700**2, 700, 1])\n","\n","        # Calculate the vehicle position relative to the center of the lane\n","        pos = (1280//2 - (xl+xr)//2)*xm\n","\n","        # Return curvature radius of the left and right lane lines and vehicle position\n","        return left_curveR, right_curveR, pos\n","\n","    # Handle control commands based on lane detection\n","\n","    def handle_lane_detect_command(self, speed_cmd, x_battery, x_motor):\n","        speed = 0\n","        alpha = 0\n","\n","        # If the command is to go straight\n","        if self.cmd == STRAIGHT:\n","            alpha = x_motor\n","            speed = speed_cmd\n","\n","        # If the command is to turn left\n","        if self.cmd == LEFT:\n","            if self.pos >= 0.5:\n","                alpha = 35 + x_battery\n","                speed = speed_cmd - 45 + x_battery\n","            elif self.pos >= 0.4:\n","                alpha = 30 + x_battery\n","                speed = speed_cmd - 40 + x_battery\n","            elif self.pos >= 0.3:\n","                alpha = 25 + x_battery\n","                speed = speed_cmd - 30 + x_battery\n","            elif self.pos >= 0.2:\n","                alpha = 20 + x_battery\n","                speed = speed_cmd - 20 + x_battery\n","            elif self.pos >= 0.1:\n","                alpha = 15 + x_battery\n","                speed = speed_cmd - 15 + x_battery\n","\n","        # If the command is to turn right\n","        if self.cmd == RIGHT:\n","            if self.pos <= -0.5:\n","                alpha = 35 + x_battery\n","                speed = speed_cmd - 45 + x_battery\n","            elif self.pos <= -0.4:\n","                alpha = 30 + x_battery\n","                speed = speed_cmd - 40 + x_battery\n","            elif self.pos <= -0.3:\n","                alpha = 25 + x_battery\n","                speed = speed_cmd - 30 + x_battery\n","            elif self.pos <= -0.2:\n","                alpha = 20 + x_battery\n","                speed = speed_cmd - 20 + x_battery\n","            elif self.pos <= -0.1:\n","                alpha = 15 + x_battery\n","                speed = speed_cmd - 15 + x_battery\n","            speed += x_motor\n","            alpha += x_motor\n","\n","        # Create a control command string\n","        command = f\"{self.cmd} {speed} {int(alpha)}\"\n","\n","        return command"]},{"cell_type":"markdown","metadata":{"id":"L_pk1Bdj-eYI"},"source":["### Xây Dựng Mô Hình Phát Hiện Vạch Làn Đường\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["Đáp án bài tập 4"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class LaneDetection:\n","    def __init__(self):\n","        self.calibration = CameraCalibration(\n","            r'..\\Other\\CameraCalibration', 9, 6)\n","        self.thresholding = Thresholding()\n","        self.transform = PerspectiveTransformation()\n","        self.lanelines = LaneLines()\n","\n","    def forward(self, image):\n","        # Create a copy of the input image\n","        output_image = np.copy(image)\n","        # Remove lens distortion caused by the camera\n","        undistort_image = self.calibration.undistort(image)\n","        # Change the image perspective to a top-down view\n","        bird_eye_image = self.transform.forward(undistort_image)\n","        # Apply thresholding to extract lane line pixels\n","        threshold_image = self.thresholding.forward(bird_eye_image)\n","        # Detect lane lines\n","        laneline_image = self.lanelines.forward(threshold_image)\n","        # Restore the image to its original perspective\n","        laneline_image = self.transform.backward(laneline_image)\n","\n","        # Blend the processed image with the original image\n","        output_image = cv2.addWeighted(output_image, 1, laneline_image, 0.6, 0)\n","        # Draw additional information (lane direction, curvature, etc.) on the processed image\n","        output_image = self.lanelines.plot(output_image)\n","        # Return the final processed image\n","        return output_image\n","\n","    # Process the input image and detect lane lines in real-time\n","    def process_image_rt(self, image):\n","        output_image = self.forward(image)\n","        return output_image"]},{"cell_type":"markdown","metadata":{"id":"LNri3bRCAZ69"},"source":["### Khai báo các hàm số\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iZJwIsxh6Xjz"},"outputs":[],"source":["from queue import Queue\n","lane_detection = LaneDetection()\n","queue_image = Queue()\n","MAX_QUEUE_SIZE = 3\n","\n","SPEED_CMD = 150\n","X_BATTERY = 0\n","X_MOTOR = -5"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import socket\n","\n","IMAGE_RESIZE_DIMS = (1280, 720)     # Image dimensions\n","END_MARKER = b'\\xff\\xd9'            # End marker for image data\n","BUFFER_SIZE = 2048                  # Buffer size\n","\n","\n","def create_udp_socket_listen(ip, port):\n","    \"\"\"Create and bind a UDP socket for receiving data\"\"\"\n","    # Create a UDP socket\n","    sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n","    # Bind the socket to the IP address and port\n","    sock.bind((ip, port))\n","    return sock\n","\n","\n","def create_udp_socket_send():\n","    \"\"\"Create and configure a UDP socket for sending data\"\"\"\n","    # Create a UDP socket\n","    sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n","    # Configure the socket for sending data\n","    sock.setsockopt(socket.SOL_SOCKET, socket.SO_BROADCAST, BUFFER_SIZE)\n","    return sock"]},{"cell_type":"markdown","metadata":{"id":"YXF0TmCXAc2J"},"source":["### Lấy dữ liệu hình ảnh\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"REP3v9uE6Xj0"},"outputs":[],"source":["def get_image():\n","    \"\"\"Receive images via UDP and place them into a queue.\"\"\"\n","\n","    # Create a UDP socket to receive image data\n","    sock = create_udp_socket_listen(ip_lap, port_lap)\n","    print(f\"Listening on IP {ip_lap}, UDP port {port_lap}\")\n","\n","    # Initialize a bytearray to store received image data\n","    image_data = bytearray()\n","\n","    global stop_event\n","    # Loop continues until a stop signal is received\n","    while not stop_event.is_set():\n","        # Receive data from the socket with a specified buffer size\n","        data, _ = sock.recvfrom(BUFFER_SIZE)\n","        # Append the received data to the bytearray\n","        image_data.extend(data)\n","\n","        # Check if the entire image has been received\n","        if data.endswith(END_MARKER):\n","            try:\n","                # Convert the byte data to a numpy array with dtype uint8\n","                image_array = np.frombuffer(image_data, dtype=np.uint8)\n","                # Decode the numpy array into an image using OpenCV\n","                image = cv2.imdecode(image_array, cv2.IMREAD_COLOR)\n","                # Resize the image to the specified dimensions\n","                image = cv2.resize(image, IMAGE_RESIZE_DIMS)\n","                # Place the image into the queue\n","                queue_image.put(image)\n","\n","                # If the queue size exceeds the maximum limit, remove the oldest image\n","                if queue_image.qsize() >= MAX_QUEUE_SIZE:\n","                    queue_image.get()\n","            except Exception as e:\n","                # Print an error message if there is an issue with image processing\n","                print(f\"Failed to convert image: {str(e)}\")\n","\n","            # Reinitialize the bytearray for the next image\n","            image_data = bytearray()\n","\n","    # Close the socket when stopping\n","    sock.close()"]},{"cell_type":"markdown","metadata":{"id":"VVdRscRBA_tX"},"source":["### Phát hiện làn đường\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LRJhexPbA8ZP"},"outputs":[],"source":["import time\n","\n","\n","def process_image():\n","    global stop_event\n","    # Save the current time to calculate FPS\n","    prev_time = time.time()\n","    # Count the number of frames processed\n","    frame_count = 0\n","    # Variable to store FPS\n","    fps = 0\n","    # Previous control command for comparison\n","    prev_cmd = f\"{STOP} {0} {0}\"\n","\n","    # Create a UDP socket for sending data\n","    sock = create_udp_socket_send()\n","\n","    # Main loop continues until a stop signal is received\n","    while not stop_event.is_set():\n","        try:\n","            # Get an image from the queue\n","            image = queue_image.get()\n","\n","            # Calculate FPS\n","            frame_count += 1\n","            tmp_time = time.time() - prev_time\n","            if tmp_time >= 1:\n","                fps = frame_count / tmp_time\n","                prev_time = time.time()\n","                frame_count = 0\n","\n","            # Process the image to detect lane lines\n","            image = lane_detection.process_image_rt(image)\n","            # Process control commands based on lane detection\n","            cmd = lane_detection.lanelines.handle_lane_detect_command(\n","                SPEED_CMD, X_BATTERY, X_MOTOR)\n","\n","        except Exception as e:\n","            # If there is an error processing the image, display an error message on the image\n","            cv2.putText(image, \"None\", (150, 30),\n","                        cv2.FONT_HERSHEY_PLAIN, 2, (0, 255, 0), 2)\n","            # Default control command in case of an error\n","            cmd = f\"{STOP} {0} {0}\"\n","\n","        # Send control command to the vehicle controller\n","        if cmd != prev_cmd:\n","            try:\n","                # Convert control command to byte data\n","                data_bytes_cmd = cmd.encode()\n","                # Send data to the camera's IP address and port\n","                sock.sendto(data_bytes_cmd, (ip_cam, port_cam))\n","                print(f\"Sent UDP command: '{cmd}' to {ip_cam}:{port_cam}\")\n","                # Update the previous control command\n","                prev_cmd = cmd\n","\n","            except Exception as e:\n","                print(f\"Error sending UDP command: {e}\")\n","\n","        # Display FPS on the image\n","        cv2.putText(image, f\"FPS: {int(fps)}\", (10, 30),\n","                    cv2.FONT_HERSHEY_PLAIN, 2, (0, 255, 0), 2)\n","        # Display the image with processed information\n","        cv2.imshow(\"Detected Image\", image)\n","\n","        # Exit the loop if the 'Esc' key is pressed\n","        if cv2.waitKey(1) & 0xFF == 27:\n","            # Send stop command when exiting\n","            cmd = f\"{STOP} {0} {0}\"\n","            data_bytes = cmd.encode()\n","\n","            try:\n","                # Send the stop command to the vehicle controller\n","                sock.sendto(data_bytes, (ip_cam, port_cam))\n","                print(f\"Sent final UDP command: '{\n","                      cmd}' to {ip_cam}:{port_cam}\")\n","            except Exception as e:\n","                print(f\"Error sending final UDP command: {e}\")\n","\n","            stop_event.set()\n","            break\n","\n","    # Close the socket and destroy OpenCV windows\n","    sock.close()\n","    cv2.destroyAllWindows()"]},{"cell_type":"markdown","metadata":{"id":"8iSRZip7Byt1"},"source":["Đáp án bài tập 5"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0ObMQO4z6Xj0"},"outputs":[],"source":["import threading\n","stop_event = threading.Event()\n","\n","ip_lap = \"192.168.109.106\"\n","port_lap = 3000\n","\n","ip_cam = \"192.168.109.105\"\n","port_cam = 3001\n","\n","# Create two threads\n","threads = [\n","    # Thread 1 will execute the get_image function to receive images via UDP and place them into the queue\n","    threading.Thread(target=get_image,\n","                     name='GetSendImageThread'),\n","    # Thread 2 will execute the process_image function to process images and send control commands\n","    threading.Thread(target=process_image,\n","                     name='ProcessImageThread'),\n","]\n","\n","for thread in threads:\n","    thread.start()\n","\n","for thread in threads:\n","    thread.join()\n","\n","# Close all OpenCV windows after threads have completed\n","cv2.destroyAllWindows()"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"}},"nbformat":4,"nbformat_minor":0}
